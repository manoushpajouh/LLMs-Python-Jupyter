# -*- coding: utf-8 -*-
"""AI Image Classification Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sh5NjALasV8kcgDzZhZSTVimdITF54E3

Implement a house number recognition model. The dataset to train the model is
the [SVHN dataset](http://ufldl.stanford.edu/housenumbers/). There are two
variants of the dataset: one with the full numbers and one containing cropped
images corresponding to the digits 0-9. This model uses the later. Each image
is a 32x32 RGB image. The model will classify each image into one of the 10
classes corresponding to the digits. The desired accuracy is **90%**.
Additionally, the module implements data augmentation to observe its effects on
the training process.

Work with the PyTorch library.
Prepare to use Pytorch Lightning or adapt to pure Pytorch.

The objectives are to
1. implement a convolutional neural network given a pre-defined architecture
2. implement data augmentation
"""

! pip install lightning

"""# Implementation

"""

# imports

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split

import lightning as pl

# for visualization purposes
import matplotlib.pyplot as plt

# fix random seed
pl.seed_everything(100)

# load the datasets
train_dataset = torchvision.datasets.SVHN(
    root='./data', split='train', download=True)
test_dataset = torchvision.datasets.SVHN(
    root='./data', split='test', download=True)    # don't use this dataset for development !

# visualize a random image and its label
index = torch.randint(0, len(train_dataset), (1,)).item()
img, label = train_dataset[index]
print(f"Label: {label}")
display(img)

# transform the datasets so that we can work with it in pytorch
dataset_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
train_dataset.transform = dataset_transform
test_dataset.transform = dataset_transform

# convert the datasets into DataLoaders and split into training and validation sets
from torch.utils.data import DataLoader, random_split

dev_length = int(0.2*len(train_dataset))
# split the training dataset; I suggest the proportion 0.8 for train and 0.2 for dev
train, dev = random_split(
    train_dataset, [int(len(train_dataset) - dev_length), dev_length]) 
train_loader = DataLoader(train, batch_size=64, shuffle=True)
dev_loader = DataLoader(dev, batch_size=64)
test_loader = DataLoader(test_dataset, batch_size=64)

"""## NN module

Below is a structure of the neural network. It has three convolutional layers,
each with the ReLU activation function. Each convolutional layer is then passed
through a max-pooling layer (this basically picks the maximum value in each 2x2
patch of the image, reducing the size by half). On top of the third convolutional
layer, there are two fully-connected layers which yield the final prediction.

The convolutions have been defined.

The first convolution should have a kernel of size 3x3. We want to use padding.
The number of input channels should correspond to the number of channels in the
input images (they are RGB images, there is no alpha channel).

The second and third convolutional layers also have a kernel of size 3x3. 
We want to use padding.

Refer to the documentation used to fill out the parameters correctly:
[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).
"""

 # input channel is 3 because rgb image (channel 1 = r, 2=g, 3=b)
input_channels = 3
# kernel size is 3x3 and defined as a tuple
kernel_size_conv1 = (3, 3)
# same as above
kernel_size_conv2 = (3, 3)
# same as above
kernel_size_conv3 = (3, 3)
# padding should be 1 (same padding) in order for the kernel to work
padding_conv1 = 1
# same as above
padding_conv2 = 1
# same as above
padding_conv3 = 1
# originally set to 0.01, randomly chosen by user, may be updated later
learning_rate = 0.001

class SVHNCNN(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size_conv1, 
                               padding=padding_conv1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size_conv2, padding=padding_conv2)
        self.conv3 = nn.Conv2d(64, 64, kernel_size_conv3, padding=padding_conv3)
        self.fc1 = nn.Linear(64 * 4 * 4, 64)
        self.fc2 = nn.Linear(64, 10)
        self.criterion = nn.CrossEntropyLoss()
        self.learning_rate = learning_rate


    def forward(self, x):
        x = self.pool(nn.functional.relu(self.conv1(x)))
        x = self.pool(nn.functional.relu(self.conv2(x)))
        x = self.pool(nn.functional.relu(self.conv3(x)))
        x = x.view(-1, 64 * 4 * 4)
        x = nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def training_step(self, batch, batch_idx):
        # calculate loss using a suitable loss function
        x, y = batch
        y_hat = self(x)
        loss = self.criterion(y_hat, y)
        return loss

    def validation_step(self, batch, batch_idx):
        # calculate loss using a suitable loss function
        x, y = batch
        y_hat = self(x)
        val_loss = self.criterion(y_hat, y)
        self.log("val_loss", val_loss)

    def test_step(self, batch, batch_idx):
        # calculate loss and accuracy
        x, y = batch
        y_hat = self(x)
        #did not have same variable from lecture --> googled what to do instead
        accuracy = (y_hat.argmax(dim=1) == y).float().mean()
        test_loss = self.criterion(y_hat, y)
        self.log("test_loss", test_loss)
        self.log("accuracy", accuracy)

    def configure_optimizers(self):
        # define a suitable optimizer
        return optim.Adam(self.parameters(), lr=self.learning_rate)

"""Since we are comparing models trained on two datasets of different sizes,
we defined the number of training steps instead of the number of epochs.
(Defining the number of epochs would mean that the model with the larger training
dataset is trained on more examples in total, meaning that the comparison
wouldn't be fair. Setting the number of training steps ensures that both models
see the same total number of examples.)

The number of training steps is set to the length of one of the datasets
multiplied by the number of epochs you want to train for to approximate setting
just the max_epochs parameter.
"""

# set a suitable value of max_steps: len x epoch number (start w 10, change later)
max_steps = len(train_loader) * 10

# accelerator will transfer your data onto the GPU
trainer = pl.Trainer(max_steps=max_steps, accelerator="gpu")

model1 = SVHNCNN()
# train model1 on the train_loader data; validate on dev_loader
trainer.fit(model1, train_dataloaders=train_loader, val_dataloaders=dev_loader)

"""## Data augmentation

In this section, you will try to augment the dataset. You will take the `train`
subset of the original dataset, apply some transforms to it and mix it with the
original untransformed data.

You can see the list of available transforms here:
[torchvision.transforms](https://pytorch.org/vision/0.9/transforms.html).
I recommend trying, for example, `RandomHorizontalFlip` or `RandomRotation`.
"""

import copy
from torch.utils.data import ConcatDataset

train_aug = copy.deepcopy(train)
augmentation_transforms = transforms.Compose([
    transforms.ToTensor(),
    # normalize data
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    transforms.RandomRotation(10)           # transform dataset with changed hue


])
train_aug.dataset.transforms = augmentation_transforms
# we combined the augmented and unaugmented datasets
train_aug_loader = DataLoader(ConcatDataset([train, train_aug]), batch_size=64, shuffle=True)
# fix random seed
pl.seed_everything(100)

# initialize a second trainer
trainer2 = pl.Trainer(max_steps=max_steps, accelerator="gpu")
model2 = SVHNCNN()
# train model2 on the train_aug_loader data; validate on dev_loader
trainer2.fit(model2, train_dataloaders=train_aug_loader, val_dataloaders=dev_loader)

# test both your models on test_loader
# don't use test_loader before this step!
trainer.test(model1, test_loader)
trainer2.test(model2, test_loader)
